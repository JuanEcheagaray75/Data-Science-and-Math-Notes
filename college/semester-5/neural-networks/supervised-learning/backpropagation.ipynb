{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8isH3SzaKdWe"
      },
      "outputs": [],
      "source": [
        "# Implementa una red neuronal artificial de 4 capas para reconocer los dígitos escritos a mano del MNIST\n",
        "# Fuente: https://towardsdatascience.com/backpropagation-from-scratch-how-neural-networks-really-work-36ee4af202bf\n",
        "\n",
        "# TensorFlow y tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Librerias de ayuda\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Funciones de ayuda\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tqdm.autonotebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1yWCLjVKdWg"
      },
      "outputs": [],
      "source": [
        "# carga y divide el conjunto de datos MNIST para entrenamiento y prueba\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train_orig, y_train_orig), (x_test_orig, y_test_orig) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH8imXV-wxcu"
      },
      "outputs": [],
      "source": [
        "# normaliza los valores de los pixels de entrada al rango 0-1\n",
        "x_train = np.reshape(x_train_orig / 255, (-1, 784))\n",
        "x_test = np.reshape(x_test_orig / 255, (-1, 784))\n",
        "\n",
        "# convierte los datos numéricos de salida a su representación one-hot\n",
        "y_train = to_categorical(y_train_orig)\n",
        "y_test = to_categorical(y_test_orig)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KudimBRPKdWh"
      },
      "outputs": [],
      "source": [
        "def nn_init(lsize):\n",
        "    # nombres de las capas legibles para humanos para mayor claridad\n",
        "    input_layer  = lsize[0]\n",
        "    hidden_1     = lsize[1]\n",
        "    hidden_2     = lsize[2]\n",
        "    output_layer = lsize[3]\n",
        "    \n",
        "    # reduciendo la desviación estándar por tamaño de capa, con np.sqrt()\n",
        "    # las capas grandes tienen valores iniciales más ajustados\n",
        "    nnet = {\n",
        "        'w0': np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
        "        'w1': np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
        "        'w2': np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
        "    }\n",
        "    return nnet\n",
        "\n",
        "# definición de unidades x capas (de entrada, ocultas y de salida)\n",
        "layer_sizes = [x_train[0].shape[0], 128, 64, y_train[0].shape[0]]\n",
        "model = nn_init(layer_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KrCRlB6bKdWh"
      },
      "outputs": [],
      "source": [
        "# simula la red evaluandola mediante la propagación hacia delante\n",
        "def forward_pass(x):\n",
        "    # el modelo es una variable global, utilizada aquí de solo lectura\n",
        "    \n",
        "    # Estado NN: sumas internas, salidas de neuronas\n",
        "    nn_state = {}\n",
        "    \n",
        "    # \"salida cero\" es la salida de los receptores = entrada a la primera capa en el NN\n",
        "    # estas son activaciones para la capa de entrada\n",
        "    nn_state['o0'] = x\n",
        "    \n",
        "    # de la capa de entrada a la capa oculta 1\n",
        "    # suma ponderada de todas las activaciones, luego activación sigmoide\n",
        "    nn_state['z1'] = np.dot(model['w0'], nn_state['o0'])\n",
        "    nn_state['o1'] = sigmoid(nn_state['z1'])\n",
        "    \n",
        "    # de la capa oculta 1 a la capa oculta 2\n",
        "    nn_state['z2'] = np.dot(model['w1'], nn_state['o1'])\n",
        "    nn_state['o2'] = sigmoid(nn_state['z2'])\n",
        "    \n",
        "    # de la capa oculta 2 a la salida\n",
        "    nn_state['z3'] = np.dot(model['w2'], nn_state['o2'])\n",
        "    nn_state['o3'] = softmax(nn_state['z3'])\n",
        "    \n",
        "    return nn_state\n",
        "\n",
        "# calcula los gradientes mediante las derivadas parciales del error los \n",
        "# pesos de todas las capas\n",
        "def backward_pass(x, y):\n",
        "    # hacer la propagación hacia adelante, registra el estado de la red\n",
        "    nn_state = forward_pass(x)\n",
        "    \n",
        "    # pequeños deltas: derivadas del error con respecto a z\n",
        "    nn_state['d3'] = nn_state['o3'] - y\n",
        "    nn_state['d2'] = np.dot(nn_state['d3'], model['w2']) * softmax(nn_state['z2'], derivative = True)\n",
        "    nn_state['d1'] = np.dot(nn_state['d2'], model['w1']) * sigmoid(nn_state['z1'], derivative = True)\n",
        "    \n",
        "    # grandes deltas: ajustes de pesos\n",
        "    nn_state['D2'] = np.outer(nn_state['d3'], nn_state['o2'])\n",
        "    nn_state['D1'] = np.outer(nn_state['d2'], nn_state['o1'])\n",
        "    nn_state['D0'] = np.outer(nn_state['d1'], nn_state['o0'])\n",
        "    \n",
        "    return nn_state\n",
        "\n",
        "# calcula la función de costo de entropía cruzada binaria\n",
        "def part_cost(o, y):\n",
        "    c = np.dot(y, np.log(o)) + np.dot((1 - y), np.log(1 - o))\n",
        "    return -c\n",
        "\n",
        "# calcula la función de activación sigmoidea y su derivada\n",
        "def sigmoid(x, derivative = False):\n",
        "    if derivative:\n",
        "        return np.exp(-x) / ((np.exp(-x) + 1) ** 2)\n",
        "    else:\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# calcula la función de activación softmax y su derivada\n",
        "def softmax(x, derivative = False):\n",
        "    # para la estabilidad, cambiamos los valores hacia abajo para que max = 0\n",
        "    # https://cs231n.github.io/linear-classify/#softmax\n",
        "    exp_shifted = np.exp(x - x.max())\n",
        "    if derivative:\n",
        "        return exp_shifted / np.sum(exp_shifted, axis = 0) * (1 - exp_shifted / np.sum(exp_shifted, axis = 0))\n",
        "    else:\n",
        "        return exp_shifted / np.sum(exp_shifted, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Az69UYoxKdWj"
      },
      "outputs": [],
      "source": [
        "# hiperparámetros\n",
        "epochs = 5     # número de epocas de entrenamiento\n",
        "t_rate = 0.01  # razón de aprendizaje\n",
        "\n",
        "# entrena\n",
        "print('################### entrenando ####################')\n",
        "for e in range(epochs):\n",
        "    print('epoca:', e)\n",
        "    \n",
        "    samples = x_train.shape[0]\n",
        "    cost = 0\n",
        "    hit_count = 0\n",
        "    for i in tqdm(range(samples)):\n",
        "        m_state = backward_pass(x_train[i], y_train[i])\n",
        "        # add partial cost\n",
        "        cost += part_cost(m_state['o3'], y_train[i])\n",
        "        \n",
        "        # gradiente descendiente estocástico\n",
        "        # actualiza los pesos\n",
        "        model['w0'] -= t_rate * m_state['D0']\n",
        "        model['w1'] -= t_rate * m_state['D1']\n",
        "        model['w2'] -= t_rate * m_state['D2']\n",
        "        \n",
        "        if np.argmax(m_state['o3']) == np.argmax(y_train[i]):\n",
        "            # detección exitosa\n",
        "            hit_count += 1\n",
        "\n",
        "    # evaluación del desempeño\n",
        "    cost = cost / samples\n",
        "    accuracy = hit_count / samples\n",
        "    print('costo:', cost, 'exactitud:', accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLwcNT8qKdWk"
      },
      "outputs": [],
      "source": [
        "# prueba\n",
        "import os\n",
        "import pickle\n",
        "# salva el modelo usando pickle\n",
        "with open('model.pickle', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "    \n",
        "print('################### evaluando ####################')\n",
        "\n",
        "# carga el modelo salvado con pickle\n",
        "if os.path.isfile('model.pickle'):\n",
        "    with open('model.pickle', 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "\n",
        "# ejecutar todos los datos de prueba\n",
        "samples = x_test.shape[0]\n",
        "cost = 0\n",
        "hit_count = 0\n",
        "for i in tqdm(range(samples)):\n",
        "    m_state = forward_pass(x_test[i])\n",
        "    cost += part_cost(m_state['o3'], y_test[i])\n",
        "    if np.argmax(m_state['o3']) == np.argmax(y_test[i]):\n",
        "        hit_count += 1\n",
        "\n",
        "# evaluar el desempeño\n",
        "cost = cost / samples\n",
        "accuracy = hit_count / samples\n",
        "print('costo:', cost, 'exactitud:', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdXQdkSyKdWk"
      },
      "source": [
        "# Muestras de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05AHoKbLKdWl"
      },
      "outputs": [],
      "source": [
        "# graficar la cuarta imagen de entrenamiento\n",
        "plt.imshow(np.reshape(x_train[3], (28, 28)));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33hS6V5BKdWm"
      },
      "outputs": [],
      "source": [
        "# resultado esperado para la cuarta imagen\n",
        "y_train[3].astype(int).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAsAZWFtKdWn"
      },
      "outputs": [],
      "source": [
        "# grafica la 16va imagen de entrenamiento\n",
        "plt.imshow(np.reshape(x_train[15], (28, 28)));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BoAse38KdWo"
      },
      "outputs": [],
      "source": [
        "# resultado esperado para la 16va imagen\n",
        "y_train[15].astype(int).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81GlJDw5KdWo"
      },
      "source": [
        "# Función Sigmoidea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YapYMyTAKdWp"
      },
      "outputs": [],
      "source": [
        "# grafica la curva sigmoidea\n",
        "x = np.arange(-10, 10, 0.1)\n",
        "y = 1 / (1 + np.exp(-x))\n",
        "plt.rcParams[\"figure.figsize\"] = (9, 5)\n",
        "plt.rcParams['axes.spines.right'] = False\n",
        "plt.rcParams['axes.spines.top'] = False\n",
        "plt.rcParams['axes.xmargin'] = 0\n",
        "plt.rcParams['axes.ymargin'] = 0.01\n",
        "plt.rcParams['axes.grid'] = True\n",
        "plt.rcParams['axes.titlesize'] = 'x-large'\n",
        "plt.rcParams['grid.alpha'] = 0.5\n",
        "plt.rcParams['legend.frameon'] = False\n",
        "plt.rcParams['legend.fontsize'] = 'x-large'\n",
        "plt.rcParams['lines.marker'] = ''\n",
        "plt.rcParams['lines.markersize'] = 4\n",
        "plt.rcParams['lines.linewidth'] = 4\n",
        "plt.rcParams['xtick.labelsize'] = 'x-large'\n",
        "plt.rcParams['ytick.labelsize'] = 'x-large'\n",
        "plt.rcParams['figure.subplot.top'] = 0.98\n",
        "plt.rcParams['figure.subplot.bottom'] = 0.05\n",
        "plt.rcParams['figure.subplot.left'] = 0.05\n",
        "plt.rcParams['figure.subplot.right'] = 0.98\n",
        "plt.plot(x, y);"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "backpropagation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}